{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyCall\n",
    "\n",
    "まず、PyCall について簡単に説明します。\n",
    "\n",
    "PyCall の実態は「**Ruby から libpython.so を使うための拡張ライブラリ**」です。\n",
    "PyCall は libpython.so の機能を利用して、Ruby から Python のオブジェクトを触れるようにするブリッジ機能を提供します。\n",
    "PyCall を使うと、例えば以下のように Python 側の `sin` 関数を Ruby 側に持ってきて呼び出すことが可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'pycall'\n",
    "\n",
    "# PyCall.import_module function loads a module in Python, and brings the loaded module object in Ruby\n",
    "pymath = PyCall.import_module('math')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accessing `sin` attribute of `math` module\n",
    "pymath.sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calling function object by the syntax sugar of `.call` method call\n",
    "pymath.sin.(Math::PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ruby 側に持ってきた Python オブジェクトは、基本的なクラスを除いてすべて PyObject クラスのインスタンスによってラップされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pymath is a module object in Python, but it is wrapped by an instance of PyObject in Ruby\n",
    "pymath.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pymath.sin is a builtin-function object in Python, but it is wrapped by an instance of PyObject in Ruby\n",
    "pymath.sin.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The result of pymath.sin is a float object in Python, but it is automatically converted to Float object in Ruby\n",
    "pymath.sin.(Math::PI).class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The name of a function object\n",
    "pymath.sin.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It is converted to a String object in Ruby\n",
    "pymath.sin.__name__.class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pycall/import` が提供する機能を利用すると、Python での `import math` と同じような記法でモジュールをインポートできます。\n",
    "\n",
    "やってみましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'pycall/import'\n",
    "include PyCall::Import\n",
    "\n",
    "pyimport :math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math.sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "math.sin.(Math::PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "PyCall は PyObjectWrapper というモジュールを提供しています。このモジュールを使うと、Python のクラスに対応するラッパークラスを定義できます。ラッパークラスを定義すると、インスタンスメソッドやクラスメソッドの呼び出しを自然に記述できるようになります。\n",
    "\n",
    "numpy を例に違いを見てみましょう。\n",
    "\n",
    "まず、ラッパークラスを定義せずに numpy を使ってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyimport :numpy, as: :np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `np.array` retrives a function object\n",
    "np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `.call` method to call `np.array`\n",
    "ary = np.array.([*1..20].map { rand })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a PyObject\n",
    "ary.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `ary.mean` retrieves a function object\n",
    "ary.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `.call` method to call `ary.mean`\n",
    "ary.mean.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、ラッパークラスを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module Numpy\n",
    "  class NDArray\n",
    "    include PyCall::PyObjectWrapper\n",
    "    wrap_class PyCall.import_module('numpy').ndarray\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで Numpy::NDArray クラスが np.ndarray のラッパーになりました。\n",
    "\n",
    "もう一度 ndarray オブジェクトを生成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ary2 = np.array.([*1..20].map { rand + 10 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ary2 is a Numpy::NDArray!!\n",
    "ary2.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ary2.mean calls mean method!!\n",
    "ary2.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このように、PyObjectWrapper を利用して Python クラスのラッパーを Ruby 側に定義できました。\n",
    "matplotlib のラッパーライブラリでは、この機能を使って Figure や Axes などのクラスのラッパーを定義しています。\n",
    "\n",
    "残念ながら pandas の DataFrame ライブラリに対して wrap_class を適用するとエラーが出てしまう[問題があります](https://github.com/mrkn/pycall/issues/16)。\n",
    "そのため、このチュートリアルでは pandas のラッパーを定義せずに使っていきます。\n",
    "\n",
    "モジュールに対するラッパーを定義する機能はまだ作っていませんが、近日中に提供できる予定になっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Ruby using PyCall\n",
    "\n",
    "それでは、PyCall を利用して Ruby でデータ分析をやってみましょう。\n",
    "\n",
    "## 準備編\n",
    "\n",
    "分析に入る前に、いくつか準備をします。\n",
    "\n",
    "データの可視化のために seaborn ライブラリを利用します。このライブラリは matplotlib を利用しているため、IRuby と matplotlib の間の連携を有効にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'matplotlib/iruby'\n",
    "Matplotlib::IRuby.activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用するライブラリをインポートしておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyimport :pandas, as: :pd\n",
    "pyimport :seaborn, as: :sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas のデータフレームを IRuby ノートブック上で見やすく表示するための準備をします。\n",
    "これは、将来的には require 'pandas/iruby' などで自動的に実施されるようにする予定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "module Pandas\n",
    "  class DataFrame < PyCall::PyObject\n",
    "  end\n",
    "end\n",
    "\n",
    "PyCall::Conversions.python_type_mapping(pd.DataFrame, Pandas::DataFrame)\n",
    "\n",
    "dataframe_max_rows = 20\n",
    "\n",
    "IRuby::Display::Registry.module_eval do\n",
    "  type { Pandas::DataFrame }\n",
    "  format \"text/html\" do |pyobj|\n",
    "    pyobj.to_html.(max_rows: dataframe_max_rows, show_dimensions: true, notebook: true)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ分析の実演\n",
    "\n",
    "### データの準備と前処理\n",
    "\n",
    "タイタニック号の乗客のデータを用いて、乗客の生存予測をするためのモデルを作ってみます。\n",
    "\n",
    "seaborn ライブラリの `load_dataset` 関数を使ってデータのダウンロードと読み込みをします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sns.load_dataset.('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変数 `df` に代入されたオブジェクトは pandas のデータフレームです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "データ解析の最初のステップは、データの内容を観察することから始まります。\n",
    "\n",
    "上の表を見るとわかるように、このデータには、15個のカラムで構成されるレコードが890行あります。\n",
    "これらのカラムのうち、以下のように内容が重複しているものがあります。\n",
    "\n",
    "- `survived` は `alive` を `no` -> 0, `yes` -> 1 として変換して生成したもの\n",
    "- `embarked` は `embark_town` の頭文字\n",
    "- `pclass` は `class` を数値にしたもの\n",
    "- `sex` と `who` は、`male` => `man`, `female` => `woman` という対応関係にある\n",
    "\n",
    "内容が重複しているカラムが複数存在すると、情報量は変わらないのに処理量が増えてしまうため、これらを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop.([:alive, :embark_town, :class, :who], axis: 1)\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうして残ったカラムは次のような意味を持っています。\n",
    "\n",
    "| カラム名 | 意味 |\n",
    "|:--- |:--- |\n",
    "| `survived`   | 1: 生存, 0: 死亡 |\n",
    "| `pclass`     | 乗客クラス (1: Upper, 2: Middle, 3: Lower) |\n",
    "| `sex`        | 性別 (`male`: 男性, `female`: 女性) |\n",
    "| `age`        | 年齢 (1歳未満は小数) |\n",
    "| `sibsp`      | 同乗している兄弟・配偶者の人数 |\n",
    "| `parch`      | 同乗している親・子供の人数 |\n",
    "| `fare`       | チケット料金 |\n",
    "| `embarked`   | 乗船した都市名の頭文字 |\n",
    "| `adult_male` | 大人の男性の場合 true |\n",
    "| `deck`       | 客室種別 |\n",
    "| `alone`      | 一人で乗船の場合 true |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "生のデータにはほぼ確実に欠損値が含まれています。このデータの場合はどうでしょうか？調べてみましょう。\n",
    "\n",
    "データフレームの `isnull` メソッドを用いると、各行各列について欠損値の場合に `true`、そうで無い場合に `false` を対応させた同じ形のデータフレームが作られます。そのような欠損値フラグを集めたデータフレムに対して `sum` メソッドを適用することで、カラム別に欠損値の個数をカウントできます (`true` を 1, `false` を 0 として総和をとる)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull.().sum.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これより、`age` カラムには177個の欠損値、`deck` カラムには688個の欠損値が存在し、その他のカラムには欠損値が無いことがわかりました。\n",
    "\n",
    "全体で890行あるうち688個も値が欠損しているということは、`deck` カラムの値は分析には使えなさそうです。\n",
    "今回は `deck` カラムは捨てることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop.(:deck, axis: 1)\n",
    "nil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`age` カラムの分布を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampled_age = df[:age].dropna.().sample.(100) # 全てのデータを使うと少し時間がかかるのでランダムサンプリングする\n",
    "sns.kdeplot.(sampled_age, shade: true, cut: 0)\n",
    "sns.rugplot.(sampled_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あと、平均値も見てみます。せっかくなので全カラムの要約統計量を `describe` メソッドで求めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`age` の平均値は 29.699118、中央値は 28 であることが分かりました。\n",
    "\n",
    "`age` の欠損値の位置を記録しておいて、ひとまず中央値を使って欠損値を埋めることにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_isnull = df[:age].isnull.() # 欠損値の位置を記憶 (あとで使うかもしれないので)\n",
    "nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[:age].fillna.(df[:age].median.(), inplace: true) # 欠損値を中央値で埋める\n",
    "nil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう一度欠損値の個数を求めてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull.().sum.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残るは `embarked` の2つですが、2件だけなので無視して進みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生存予測をするためのモデルを作るので、予測の対象となるカラムは `survived` です。\n",
    "まず、各カラムが `survived` とどのくらい相関を持っているか見てみましょう。\n",
    "そのためには、ラベルが入っている `sex` と `embarked` の2カラムの値を数値に変換する必要があります。\n",
    "\n",
    "ラベル変数を数値変数へ変換したものをダミー変数と言い、pandas では `get_dummies` 関数を使って処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies.(df[:sex])\n",
    "embarked_dummies = pd.get_dummies.(df[:embarked])\n",
    "df = pd.concat.(PyCall.tuple(df, sex_dummies, embarked_dummies), axis: 1)\n",
    "df = df.drop.([:sex, :embarked, :S], axis: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sex` のダミー変数である `female` と `male`, および `embarked` のダミー変数である `C`, `Q` が追加されました。\n",
    "元の `sex` と `embarked` は削除しました。\n",
    "\n",
    "`embarked` のダミー変数にはもう一つ `S` が存在していますが、`C` と `Q` の両方が 0 の場合、(2件ある欠損値を除いて) `S` が 1 になっているはずです。ですから、`S` は情報量を持たないため削除しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、全てのカラムが数値データになったので、カラム間の相関係数を `corr` メソッドで求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "性別系のカラム (`female`, `male`, `adult_male`) が最も相関が高いことがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### モデリング\n",
    "\n",
    "ここでは、ランダムフォレスト ( `sklearn.ensemble.RandomForestClassifier` )、ロジスティック回帰 ( `sklearn.linear_model.LogisticRegression` )、サポートベクトルマシン ( `sklearn.svm.SVC` ) の3種類のモデルを作り、それぞれの精度を比較します。\n",
    "モデルのハイパーパラメータをグリッドサーチ ( `sklearn.model_selection.GridSearchCV` ) で最適化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyfrom 'sklearn.ensemble', import: :RandomForestClassifier\n",
    "pyfrom 'sklearn.linear_model', import: :LogisticRegression\n",
    "pyfrom 'sklearn.svm', import: :SVC\n",
    "pyfrom 'sklearn.model_selection', import: :GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ランダムフォレストによる分類モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = GridSearchCV.(\n",
    "  RandomForestClassifier.(n_jobs: 2),\n",
    "  {\n",
    "    n_estimators: [10, 20, 50],\n",
    "    max_depth: [4, 5, 6, 7],\n",
    "    max_features: [:auto, :log2, PyCall.None],\n",
    "  },\n",
    "  scoring: :roc_auc,\n",
    "  n_jobs: 4,\n",
    "  cv: 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_names = [:pclass, :age, :sibsp, :parch, :fare, :adult_male, :alone, :female, :male, :C, :Q]\n",
    "x = df[x_names]\n",
    "y = df[:survived]\n",
    "rfc.fit.(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グリッドサーチおよび交差検定の結果は `cv_results_` 属性に入っています。この属性の値は、そのまま pandas の DataFrame に渡せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.(data: rfc.cv_results_).drop.(:params, axis: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もっとも成績が良かったランダムフォレストモデルにおける特徴量の重要度を見てみましょう。\n",
    "\n",
    "もっとも成績が良いモデルは `best_estimator_` で取得できます。\n",
    "このモデルは RandomForestClassifier のインスタンスなので、`feature_importances_` 属性を持っています。\n",
    "これと `x_names` を seaborn の barplot を使って可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame.(data: {\n",
    "  name: x_names,\n",
    "  importance: rfc.best_estimator_.feature_importances_\n",
    "})\n",
    "sns.barplot.(x: :name, y: :importance, data: df_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`adult_male` や性別 (`female`, `male`) が大きく寄与していることがわかります。\n",
    "逆に `alone`、`C`、`Q` はほとんど寄与していません。\n",
    "\n",
    "もう一度、カラム間の相関行列を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.corr.()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`adult_male`, `female`, `male`, はどれも0.5を超える相関係数を持っていて、かつ、特徴量としての重要度も高くなっていました。\n",
    "しかし、`fare` と `alone` を見てみると、これらは同程度の相関係数になっていますが、特徴量としての重要度は `fare` は `female` と同じくらい高いのに対し、`alone` はもっとも重要度が低い特徴量でした。\n",
    "このように、単に相関係数を見るだけでは、特徴量が分類にどの程度重要になるかは分からないのです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ロジスティク回帰による分類モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrc = GridSearchCV.(\n",
    "  LogisticRegression.(n_jobs: 2),\n",
    "  {\n",
    "    penalty: [:l2, :l1],\n",
    "    C: [10.0, 1.0, 0.1, 0.01],\n",
    "  },\n",
    "  scoring: :roc_auc,\n",
    "  n_jobs: 4,\n",
    "  cv: 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrc.fit.(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.(data: lrc.cv_results_).drop.(:params, axis: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### サポートベクトルマシンによる分類モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = GridSearchCV.(\n",
    "  SVC.(kernel: :rbf),\n",
    "  {\n",
    "    C: [10.0, 1.0, 0.1, 0.01],\n",
    "    gamma: [5, 10, 15, 20].map {|x| 1.0 / x },\n",
    "  },\n",
    "  scoring: :roc_auc,\n",
    "  n_jobs: 4,\n",
    "  cv: 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc.fit.(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.(data: svc.cv_results_).drop.(:params, axis: 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame.(data: {\n",
    "  model: %w[RFC LRC SVC],\n",
    "  score: [rfc.best_score_, lrc.best_score_, svc.best_score_]\n",
    "})\n",
    "sns.barplot.(x: :model, y: :score, data: result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.4.0",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
